{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518bac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import scipy.special\n",
    "def neglogverosimilitud(theta, *args):\n",
    "    X, y = args\n",
    "    loglambda = np.dot(X, theta) \n",
    "    return -np.sum(y*loglambda - np.exp(loglambda) - scipy.special.loggamma(y+1)) \n",
    "def grad_neglogverosimilitud(theta, *args):\n",
    "    X, y = args\n",
    "    loglambda = np.dot(X, theta)    \n",
    "    error = y - np.exp(loglambda)\n",
    "    return -np.sum(error.reshape(-1,1)*X, axis=0)\n",
    "def pseudo_r2(theta, *args):\n",
    "    X, y = args\n",
    "    best_theta0 = np.mean(y)\n",
    "    logL0 = -neglogverosimilitud(np.array([best_theta0, 0., 0., 0.]), X, y)\n",
    "    return (logL0 + neglogverosimilitud(theta, X, y))/logL0\n",
    "def train_model(X, y):\n",
    "    res = scipy.optimize.minimize(fun=neglogverosimilitud, x0=0.1*np.random.randn(4), \n",
    "                                  method='BFGS', jac=grad_neglogverosimilitud,\n",
    "                                  args=(X, y), tol=1e-2)\n",
    "    return res.x\n",
    "def bootstrap(X, y, T):\n",
    "    N = len(y)\n",
    "    theta_boot = np.zeros(shape=(T, 4))\n",
    "    pr2_boot = np.zeros(shape=(T,))\n",
    "    for t in range(T):\n",
    "        idx = np.random.choice(N, N, replace=True)\n",
    "        theta_boot[t, :] = train_model(X[idx, :], y[idx])\n",
    "        pr2_boot[t] = pseudo_r2(0.1*np.random.randn(4), X[idx, :], y[idx])\n",
    "    best_theta = train_model(X, y)\n",
    "    best_pr2 = pseudo_r2(best_theta, X, y)\n",
    "    def plot_bootstrap(ax, dist, best, title):\n",
    "        pp = np.percentile(dist, [5, 95])\n",
    "        ax.hist(dist)\n",
    "        ax.axvline(best, ls='--', c='r')\n",
    "        ax.axvline(pp[0], ls='--', c='k')\n",
    "        ax.axvline(pp[1], ls='--', c='k')\n",
    "        ax.set_title(title)   \n",
    "    fig, ax = plt.subplots(2, 2, figsize=(6, 6), tight_layout=True)\n",
    "    for k, (ax_, theta) in enumerate(zip(ax.ravel(), theta_boot.T)):\n",
    "        plot_bootstrap(ax_, theta, best_theta[k], f\"theta{k}\")\n",
    "    fig, ax = plt.subplots(figsize=(3, 3), tight_layout=True)\n",
    "    plot_bootstrap(ax, pr2_boot, best_pr2, \"pseudo R2\")\n",
    "y = df[\"nbillonarios\"].values\n",
    "names = df.index.values\n",
    "ordering = np.argsort(y)[::-1]\n",
    "y = y[ordering]\n",
    "names = names[ordering]\n",
    "X = df[[\"logpibpc\", \"logpob\", \"gatt\"]].values[ordering, :]\n",
    "X = (X - np.mean(X, axis=0, keepdims=True))/np.std(X, axis=0, keepdims=True)\n",
    "X = np.concatenate((np.ones(shape=(len(y), 1)), X), axis=1)\n",
    "bootstrap(X, y, T=100)\n",
    "best_theta = train_model(X, y)\n",
    "yhat = np.exp(np.dot(X, best_theta))\n",
    "fig, ax = plt.subplots(figsize=(6, 8), tight_layout=True)\n",
    "ax.barh(range(10), y[:10], alpha=0.5, label='True')\n",
    "ax.barh(range(10), yhat[:10], alpha=0.5, label='Expected')\n",
    "plt.legend()\n",
    "ax.set_yticks(range(10))\n",
    "ax.set_yticklabels(names[:10]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
